{
  "hash": "4aa288d65391bd25d298d2538fd47dea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Experiments with MRP for small area estimation in GIScience\"\nauthor: \"Roger Beecham and Stephen Clark\"\n---\n\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\nThis document describes a workflow for generating small area outcome estimates using MRP. Originally this work formed a GISRUK abstract ([paper](https://eprints.whiterose.ac.uk/id/eprint/226795/1/mrp_gisruk.pdf) | [talk](https://www.roger-beecham.com/slides/mrp/slides.html#/title-slide)). Currently, we are turning this into a full paper, but particularly exciting are the  wider ambitions to generate a set of place-based indicators as part of Leeds [HASP](https://www.sdruk.ukri.org/data/healthy-and-sustainable-places-data-service/) data service. \n\n## Setup\n\nAs well as the usual suspects, listed below are some useful packages for working over (Bayesian) models in a *tidy* way. [`brms`](https://paulbuerkner.com/brms/) is a wrapper to Stan; [`marginaleffects`](https://marginaleffects.com) is a very useful package for generating interpretable outputs from model objects (conditional effects in this case);  and [`tidybayes`](https://mjskay.github.io/tidybayes/) for uncertainty representation extensions to `ggplot2`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(here) \nlibrary(tidyverse) \n\n# Bayesian modelling tools\nlibrary(rstanarm)\nlibrary(cmdstanr)\nlibrary(brms)\nlibrary(marginaleffects) # For extracting effect sizes from bayesian objects.\nlibrary(parameters)\nlibrary(tidybayes) # For uncertainty representation.\n\nlibrary(sf)\nlibrary(patchwork)\nlibrary(ggtext)\nlibrary(ggpubr)\n\n# library(modelsummary)\n# library(gt)\nsource(here(\"R\", \"theme_clean.R\"))\nsource(here(\"R\", \"plot_helpers.R\"))\n```\n:::\n\n\n\n## Data\n\n* Survey data (microdata) \n* Census data: Pop by usual residence in households. \n* Poststratification frame: Joint counts (and modelled joint counts) by MSOA.\n* MSOA lookup files, spatial geometry files etc.\n\n### Health Survey for England data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# HEStoFMF.R > Converts to format to be used in FMF\n# HES data (microdata)\nhes_raw <- read_csv(here(\"Data\", \"HES\", \"spss\", \"spss28\", \"HES_for_R.csv\"))\nhes_for_model <- read_csv(here(\"FMF\", \"HES\", \"HESforFMF.csv\")) |> \n  select(id=Seriala, health=genhelf1, SexbyAge, sha=SHA2, region=GOR2, is_urban=urban14b_2, imd=qimd19_2) |>\n  separate_wider_delim(col=SexbyAge, names=c(\"sex\", \"age\"), delim=\".\") |> \n  mutate(\n    # Create binary outcome variable.\n    is_good=health %in% c(\"good\",\"verygood\"),\n    # Cast 5-point as factor, for ordinal regression.\n    health=factor(health, levels=c(\"verybad\", \"bad\", \"fair\", \"good\", \"verygood\"), ordered=TRUE),\n    is_urban=is_urban==\"U\",\n    imd=case_when(\n      imd==\"Least.deprived\" ~ \"5\",\n      imd== \"X4\" ~ \"2\", \n      imd== \"X3\" ~ \"3\",\n      imd== \"X2\" ~ \"4\",\n      imd==\"Most.deprived\" ~ \"1\",\n      TRUE ~ imd\n      ),\n    across(c(sha, region), ~str_replace_all(.x, \"\\\\.\",\"_\"))\n    ) |> \n    left_join(hes_raw |>  mutate(educ= case_when(\n    topqual3 == \"NVQ4/NVQ5/Degree or equiv\" ~ \"level4\",\n    topqual3 %in% c(\"Higher ed below degree\",\"NVQ3/GCE A Level equiv\") ~ \"level3\",\n    topqual3 %in% c(\"NVQ1/CSE other grade equiv\",\"NVQ2/GCE O Level equiv\") ~ \"level1level2\",\n    topqual3 == \"Foreign/other\" ~ \"other\",\n    topqual3 %in% c(\"No qualification\",\"Refused\") ~ \"level0\",\n    topqual3 == \"Not applicable\" ~ \"na\",\n    TRUE ~ topqual3\n  )) |> \n  select(id=Seriala, educ)) |> \n    mutate(age2=case_when(\n      age %in% c(\"age0to4\", \"age5to15\") ~ \"age0to15\",\n      age %in% c(\"age65to74\", \"age75p\") ~ \"age65p\",\n      TRUE ~ age\n    )) \n```\n:::\n\n\n### Census data and poststratification frame\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Total households by MSOA\nzone_totals <- read_csv(here(\"data\", \"TS001.csv\")) |> rename(zone_id=`Zone ID`)\n\n# Groundtruth: Census data\nhealth <- read_csv(here(\"data\", \"GH.csv\")) |> rename(zone_id=`Zone ID`)\ngeog <- readxl::read_excel(here(\"data\", \"MSOA21_GOR_SHA_UR_IMD.xlsx\"), sheet=\"MSOA21\") |> \n  select(zone_id=MSOA21CD, region=GOR2, sha=SHA2, is_urban=urban14b_2, imd=IMD19_1eqMD) |> \n  mutate(\n  is_urban=is_urban==\"U\", across(c(sha, region), ~str_replace_all(.x, \"\\\\.\",\"_\")))\n\n# Poststratification frame\n# ps1 : sex by age\nps1 <- read_csv(here(\"data\", \"SexbyAge.csv\")) |> rename(zone_id=`Zone ID`) |> \n  pivot_longer(-zone_id) |> \n  separate_wider_delim(col=name, names=c(\"sex\", \"age\"), delim=\".\") |> \n  mutate(count=value) |> \n  group_by(zone_id) |> \n  mutate(zone_tot=sum(count)) |> ungroup() |> \n  group_by(zone_id, sex, age) |>\n  summarise(cell_counts=sum(count), prop=cell_counts/zone_tot) |> \n  ungroup() |> \n  left_join(geog)\n\n# ps2 : sex by age by education level\nps2 <- readxl::read_excel(here(\"data\", \"SbyAbyQual.xlsx\"), sheet=\"custom-filtered-2024-11-24T15_1\")\nnames(ps2) <- c(\"zone_id\", \"zone_name\", \"age_code\", \"age\", \"sex_code\", \"sex\", \"educ_code\", \"educ\", \"count\")\n\n# Checking for different MSOA definitions.\nmissing_msoas <- ps2 |> \n  separate_wider_delim(educ, delim=\":\", names=c(\"educ\", \"expl\"), too_few = \"align_start\") |> \n  select(zone_id, age, sex, educ, count) |> \n  left_join(geog |> select(zone_id, region)) |> filter(region!=\"Wales\") |> \n  group_by(zone_id) |>\n  summarise(zone_tot=sum(count)) |> \n  left_join(geog) |> filter(region!=\"Wales\") |> select(zone_id, region) |> unique() |> \n  left_join(ps1 |> select(zone_id, r2=region) |> unique() ) |> filter(is.na(r2)) |> pull(zone_id)\n\n# Create formatted ps dataset, matching HSE data.\nps2  <- ps2 |> \n  separate_wider_delim(educ, delim=\":\", names=c(\"educ\", \"expl\"), too_few = \"align_start\") |> \n  select(zone_id, age, sex, educ, count) |> \n  left_join(geog |> select(zone_id, region)) |> filter(region!=\"Wales\", !zone_id %in% missing_msoas) |> \n  select(-region) |> \n  mutate(\n    educ= case_when(\n      educ == \"Level 4 qualifications or above\" ~ \"level4\",\n      educ == \"Level 3 qualifications\" ~ \"level3\",\n      educ %in% c(\"Level 2 qualifications\",\"Level 1 and entry level qualifications\") ~ \"level1level2\",\n      educ == \"No qualifications\" ~ \"level0\",\n      educ == \"Does not apply\" ~ \"na\",\n      educ == \"Other\" ~ \"other\",\n      TRUE ~ as.character(educ) ),\n    sex=tolower(sex),\n    age = case_when(\n      age == \"Aged 15 years and under\" ~ \"age0to15\",\n      age == \"Aged 16 to 24 years\" ~ \"age16to24\",\n      age == \"Aged 25 to 34 years\" ~ \"age25to34\",\n      age == \"Aged 35 to 49 years\" ~ \"age35to49\",\n      age == \"Aged 50 to 64 years\" ~ \"age50to64\",\n      age == \"Aged 65 years and over\" ~ \"age65p\",\n      TRUE ~ age ),\n    ) |>\n  group_by(zone_id) |>\n  mutate(zone_tot=sum(count)) |> ungroup() |> \n  group_by(zone_id, sex, age, educ) |>\n  summarise(cell_counts=sum(count), prop=cell_counts/zone_tot) |>   \n  ungroup() |> unique() |> \n  left_join(geog)\n\n# Identify differences in MSOA codes between the HSE and MSOA lookup datasets.\n# missing_msoas <- t |> left_join(geog) |> filter(region!=\"Wales\") |> select(zone_id, region) |> unique() |> left_join(ps1|> select(zone_id, r2=region) |> unique() ) |> filter(is.na(r2)) |> pull(zone_id)\n# LIST of MSOAs not in ps1but present in ps2\n# Joining with `by = join_by(zone_id)`\n# Joining with `by = join_by(zone_id)`\n# # A tibble: 14 Ã— 3\n#    zone_id   region                   r2   \n#    <chr>     <chr>                    <chr>\n#  1 E02002524 North_East               NA   \n#  2 E02002526 North_East               NA   \n#  3 E02002693 Yorkshire_and_the_Humber NA   \n#  4 E02003897 South_West               NA   \n#  5 E02003972 North_West               NA   \n#  6 E02003974 North_West               NA   \n#  7 E02004243 South_West               NA   \n#  8 E02004631 South_West               NA   \n#  9 E02005184 North_West               NA   \n# 10 E02005327 North_West               NA   \n# 11 E02005713 North_East               NA   \n# 12 E02005721 North_East               NA   \n# 13 E02005727 North_East               NA   \n# 14 E02005915 East_Midlands            NA   \n\n# Population size of those missing MSOAs : 88536\nps2 |> left_join(geog) |> \n  filter(region!=\"Wales\", !zone_id %in% missing_msoas ) |> \n  summarise(tot=sum(cell_counts))\n# 55415266\nps1|> summarise(tot=sum(cell_counts))\n# 55415499\n# Overall difference in zone totals, with hhd also of 233.\n\n# Check levels exactly match between the survey and postratification frame.\nall.equal(\n  ps2 |> select(region) |> unique() |> arrange(region) |>  pull(),\n  hes_for_model |> select(region) |> unique() |> arrange(region) |> pull()\n)\n```\n:::\n\n\n\n### Boundary data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# MSOAs : Bring down from ONS Open Geography Portal and simplify. \n# msoa_boundaries <- st_read(\"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Middle_layer_Super_Output_Areas_December_2021_Boundaries_EW_BSC_V3/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\") |> \n# rmapshaper::ms_simplify(keep_shapes = TRUE)\n# st_write(msoa_boundaries, here(\"data\", \"msoa_boundaries.geojson\"))\nmsoa_boundaries <- st_read(here(\"data\", \"msoa_boundaries.geojson\"))\n```\n:::\n\n\n## Explore survey data: Look for bias\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Binary outcome.\ntemp_freqs <- bind_rows (\n  ps2 |> \n  select(c(sex:cell_counts, region, is_urban, imd)) |> mutate(is_urban=as.character(is_urban), imd=as.character(imd)) |> \n  pivot_longer(-c(cell_counts), names_to = \"var_name\", values_to = \"val\") |> \n  group_by(var_name, val) |> \n  summarise(count=sum(cell_counts)) |> mutate(type=\"Census\"),\n  \n  hes_for_model |> select(-c(is_good,sha, age)) |> \n  rename(age=age2) |> \n  mutate(is_urban=as.character(is_urban)) |> \n  pivot_longer(-c(id, health), names_to = \"var_name\", values_to = \"val\") |> \n  group_by(var_name, val) |> \n  summarise(count=n()) |>  mutate(type=\"HSE\")\n)\n\n# Plot\nbias_hse <- temp_freqs |> \n  pivot_wider(names_from=var_name, values_from=val) |> \n  mutate(\n    imd=case_when(\n      imd==\"1\" ~ \"1 most\",\n      imd== \"5\" ~ \"5 least\",\n      TRUE ~ imd\n      ),\n    region=case_when(\n      region==\"East_Midlands\" ~ \"EM\",\n      region==\"East_of_England\" ~ \"E\", \n      region==\"North_East\" ~ \"NE\",\n      region==\"North_West\" ~ \"NW\",\n      region==\"South_East\" ~ \"SE\",\n      region==\"South_West\" ~ \"SW\",\n      region==\"West_Midlands\" ~ \"WM\",\n      region==\"Yorkshire_and_the_Humber\" ~ \"Y&H\",\n      TRUE ~ region),\n    educ=case_when(\n      educ==\"level0\" ~ \"0. none\",\n      educ==\"level1level2\" ~ \"1. 2+ GCSEs\", \n      educ==\"level3\" ~ \"3. A-levels\", \n      educ==\"level4\" ~ \"4. degree +\",\n      educ==\"na\" ~ \"na/other\",\n       educ==\"other\" ~ \"na/other\",\n      ),\n    age=case_when(\n      age == \"age0to15\" ~ \"0-15\",\n      age == \"age16to24\" ~ \"16-24\",\n      age == \"age25to34\" ~ \"25-34\",\n      age == \"age35to49\" ~ \"35-49\",\n      age == \"age50to64\" ~ \"50-64\",\n      age == \"age65p\" ~ \"65+\"),\n    is_urban=case_when(\n      is_urban == FALSE ~ \"rural\",\n      is_urban == TRUE ~ \"urban\")\n  ) |> \n  pivot_longer(-c(count, type), names_to = \"var_name\", values_to = \"val\") |> filter(!is.na(val)) |> \n  mutate(var_name=factor(var_name, levels=c(\"sex\", \"age\", \"educ\", \"imd\", \"is_urban\", \"region\"))) |> \n  \n  group_by(type, var_name) |> \n  mutate(tot=sum(count)) |> ungroup() |> \n  group_by(type, val) |> \n  mutate(prop=count/tot) |> ungroup() |> \n  \n  ggplot(aes(x=val, y=prop)) +\n  geom_col(data=. %>% filter(type==\"HSE\"), fill=\"#636363\", alpha=.5) +\n  geom_spoke(data=. %>% filter(type==\"Census\"), angle=0, radius=.5, position=\"center_spoke\",alpha=1, linewidth=.8, colour=\"#08519c\") +\n  facet_grid(.~var_name, scales=\"free_x\", space=\"free_x\") +\n  labs(\n    y=\"% in <span style='color: #08519c;'>**Census**</span> vs <span style='color: #636363;'>**HSE**</span>\", \n    x=\"\", \n    title=\"Difference between 2021 <span style='color: #636363;'>**HSE**</span> sample and <span style='color: #08519c;'>**Census**</span> population\") +\n  theme(\n    strip.text.x = element_text(size=35),\n    axis.text.y=element_text(size=30),\n    axis.text.x=element_text(angle=270, hjust = 0, size=35),\n    axis.title.y = element_markdown(size=40),\n    plot.title = element_markdown(size=60)\n    )\nggsave(here(\"..\", \"figs\", \"bias_hse2.png\"), bias_hse, width=8, height=4.5, dpi=300)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../figs/bias_hse2.png){#fig-bias-hse width=100%}\n:::\n:::\n\n\n## Model\n\nI am following primers on MRP:\n\n* [Juan Lopez-Martin + others](https://statmodeling.stat.columbia.edu/2022/05/31/multilevel-regression-and-poststratification-case-studies/), via `brms`  and `stanarm`\n* [Solomon Kurz](https://bookdown.org/content/4857/models-with-memory.html), via `brms`\n* [Nathan Alexander](https://rohanalexander.github.io/telling_stories-published/15-mrp.html), via `stanarm`\n\nAlso, I have been consulting Andrew Heiss's detailed posts on working with logistic regression multilevel model outputs: [here](https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/#posterior-predictions) and [here](https://www.andrewheiss.com/blog/2023/08/12/conjoint-multilevel-multinomial-guide/#bayesian-comparisonscontrasts).\n\nGeneral practice in MRP is to include every variable as a random intercept / level and so fully-pool estimates of the outcome. That makes sense, but it means that it's hard to interpret and justify model-based decisions on variables included in the model. While general practice is to include as many demographics and geography variables as possible, as long as they can still compute, if we are interested in ultimately building some SPM, then it is useful to require parsimony in the variables used. But interpreting these hierarchical Bayesian  model outputs is hard. What I do here is:\n\n1. Generate posterior predictions for each level in the model and look at how narrow the CIs are for those values. This is using [marginal effects](https://marginaleffects.com/bonus/brms.html). \n\n2. Generate posterior conditional effects for each level in them, again using [marginal effects](https://marginaleffects.com/bonus/brms.html). \n\n2. Extract the \"condition_mean\", as per [Alexander 2023](https://rohanalexander.github.io/telling_stories-published/15-mrp.html) -- but I need to check what this means.\n\n\n### Priors\n\nWe parameterise our models using:\n\n1.  An informed prior on the intercept. We have some experience with stated response surveys and health outcomes. Our expectation is that most will identify as in good health -- c. 75%. So for the multilevel logistic regression, our intercept is a Gaussian set on log-odds scale,  we use $Normal(mean=0.5, sd=1)$.\n\n2. The multilevel priors are set to $exponential(1)$ as a default. \n\n3. The `adept_delta` setting is to .95 -- common when a hierarchical grouping variable has few levels.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\np <- tibble(n = rnorm(1e6, mean = 0.5, sd = 1)) |>  \n  mutate(p = brms::inv_logit_scaled(n)) |> \n  ggplot(aes(x = p)) +\n  geom_histogram(fill=\"#636363\", binwidth = .02, boundary = 0, alpha=.5) +\n  scale_y_continuous(breaks = NULL) +\n  scale_x_continuous(labels = scales::label_percent()) +\n  labs(\n    title=\"<span>theoretical **prior** on intercept</span>\", \n    x=\"baseline % **good** health\", y=\"\") +\n  theme(\n    axis.title=element_markdown(size=35), \n    plot.title = element_markdown(size=60),\n    axis.text.x=element_text(size=30)\n    )\nggsave(here(\"..\", \"figs\", \"prior.png\"), p, width=4.5, height=3, dpi=300)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../figs/prior.png){#fig-prior width=70%}\n:::\n:::\n\n\n\n### Example model specification\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(13)\n# Time difference of 5.53914 mins\nstart <- Sys.time()\nmodel7 <-\n  brm(data = hes_for_model,\n      family = bernoulli(),\n      is_good ~ sex + (1 | age2) + (1 | educ) + (1 | imd) + (1 | region) + (1 | is_urban), #+ (1 | educ:age2),\n      #is_good ~ sex + (1 | age),\n      prior = c(set_prior(\"normal(0.5, 1)\", class = \"Intercept\"),\n                set_prior(\"normal(0, 1)\", class = \"b\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"age2\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"educ\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"imd\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"region\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"is_urban\")#,\n                # set_prior(\"exponential(1)\", class = \"sd\", group=\"educ:age2\")\n                ),\n      iter = 2000, warmup = 1000, cores = 4, chains=4,\n      seed = 13,\n      backend = \"cmdstanr\", \n      control = list(adapt_delta = .95))\nprint(Sys.time()-start)\n# saveRDS(model, file = here(\"MRP\", \"fit_hse_7.rds\"))\n# saveRDS(model, file = here(\"MRP\", \"fit_hse_7_nointeract.rds\"))\n# model <- readRDS(here(\"..\", \"models\", \"fit_hse_7.rds\"))\nmodel7 <- readRDS(here(\"..\", \"models\" \"fit_hse_7_nointeract.rds\"))\n\nmodel1 <-\n  brm(data = hes_for_model,\n      family = bernoulli(),\n      is_good ~ sex + (1 | age2),\n      prior = c(set_prior(\"normal(0.5, 1)\", class = \"Intercept\"),\n                set_prior(\"normal(0, 1)\", class = \"b\"),\n                set_prior(\"exponential(1)\", class = \"sd\", group=\"age2\")\n                ),\n      iter = 2000, warmup = 1000, cores = 4, chains=4,\n      seed = 13,\n      backend = \"cmdstanr\", \n      control = list(adapt_delta = .95))\n\n# saveRDS(model1, file = here(\"..\", \"models\", \"fit_hse_1.rds\"))\nmodel1 <- readRDS(here(\"..\", \"models\", \"fit_hse_1.rds\"))\n```\n:::\n\n\n### Example analysis of model outputs\n\nThe benefit of modern packages for computational model-building (and Bayesian approach) is that we can take advantage of resampling procedures to derive more interpretable quantities for the variables included in our model. For example, we can ask about the predicted probability of a particular characteristic individual, or an individual living in a particular place, reporting a `good` health outcome. Or what the average difference in likelihood of reporting a good health outcome is for a hypothetical individual of a particular age versus a hypothetical  individual of another age group (conditional on other characteristics being consistent with the sample average). \n\nThe `marginaleffects` package provides a set of functions to do this -- to look at posterior predicted values and comparisons (contrasts) for different, user specified, individuals. There are a few key functions: \n\n* `marginaleffects::predictions()` extracts from a model the predicted probability in this case of a survey respondent reporting a `good` health outcome. To this function we supply a `newdata` argument with a grid of person characteristics that we want to predict over/for, and a `type` argument setting the scale with which to return predictions.  By default `marginaleffects::predictions()` returns for each row (respondent) in the dataset, but we might want to return predicted values for:\n  + A specific demographic combination (as in postratification frame)\n  + A hypothetical individual with each predictor held at the sample average (mean / mode).\n\n* `marginaleffects::avg_predictions()` takes the average of all predicted values of the dataset -- so imagine predicting out for each observation (respondent) and averaging out their predicted probabilities. But this becomes more useful when we pass a `by` argument to predict for actually observed values of our dataset -- e.g. for particular ages or other characteristics, what is the average probability of the outcome, given our model?\n\n* `marginaleffects::comparisons()` compares two sets of predictions made with different predictor values. The quantity of interest is the difference in predictions when, say, `age` takes on different values. This is done via parameterising the `variables` argument. Risk differences are *conditional* quantities, which vary with the values of all predictors in the model. By default we obtain the comparison (risk difference) for each unit of observation.  \n\n\nSo below, I inspect the predicted probability of good health by key demographics and comparing `model1` (using only sex and age) with `model7`, which uses many more covariates.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nvar_levels <- tibble(variable = c(\"age2\", \"educ\", \"region\", \"imd\", \"is_urban\")) %>% \n  mutate(levels = map(variable, ~{\n    x <- hes_for_model[[.x]]\n    if (is.numeric(x)) {\n      \"\"\n    } else if (is.factor(x)) {\n      levels(x)\n    } else if (is.logical(x)) {\n        levels(factor(x))\n    }\n    else {\n      sort(unique(x))\n    }\n  })) %>% \n  unnest(levels)  \n\nmodel_var_levels <- bind_rows(\n  var_levels |> filter(variable == \"age2\") |> add_column(model=\"model1\"), \n  var_levels |> add_column(model=\"model7\")\n)\n\n\nmodel_preds <- map2_df(\n  .x = list(model1, model7), \n  .y = c(\"model1\", \"model7\"),\n  ~ map_df(model_var_levels |> filter(model == .y) |> pull(variable) |> unique(),\n           function(var) {\n             avg_predictions(.x, by = var, allow_new_levels = TRUE) |> \n               posterior_draws() |>  \n               add_column(condition = var, model = .y) \n           })\n)\n\nplot_data <- model_preds |>  \n  mutate(age2 = case_when(\n      str_detect(age2, \"age\\\\d+p$\") ~ str_replace(age2, \"age(\\\\d+)p\", \"\\\\1+\"),\n      str_detect(age2, \"age\\\\d+to\\\\d+\") ~ str_replace(age2, \"age(\\\\d+)to(\\\\d+)\", \"\\\\1 - \\\\2\"),\n      TRUE ~ age2),\n    imd=case_when(\n      imd==\"1\" ~ \"1 most\",\n      imd== \"5\" ~ \"5 least\",\n      TRUE ~ imd\n      ),\n    region=case_when(\n      region==\"East_Midlands\" ~ \"EM\",\n      region==\"East_of_England\" ~ \"E\", \n      region==\"North_East\" ~ \"NE\",\n      region==\"North_West\" ~ \"NW\",\n      region==\"South_East\" ~ \"SE\",\n      region==\"South_West\" ~ \"SW\",\n      region==\"West_Midlands\" ~ \"WM\",\n      region==\"Yorkshire_and_the_Humber\" ~ \"Y&H\",\n      TRUE ~ region),\n    educ=case_when(\n      educ==\"level0\" ~ \"0. none\",\n      educ==\"level1level2\" ~ \"1. 2+ GCSEs\", \n      educ==\"level3\" ~ \"3. A-levels\", \n      educ==\"level4\" ~ \"4. degree +\",\n      educ==\"na\" ~ \"na/other\",\n      educ==\"other\" ~ \"na/other\",\n      ),\n    is_urban=case_when(\n      is_urban == FALSE ~ \"rural\",\n      is_urban == TRUE ~ \"urban\"),\n    cat_val = case_when(\n      condition == \"age2\" ~ pick(age2) |>  pull(),\n      condition == \"educ\" ~ pick(educ) |>  pull(),\n      condition == \"region\" ~ pick(region) |>  pull(),\n      condition == \"imd\" ~ pick(imd) |>  pull(),\n      condition == \"is_urban\" ~ pick(is_urban) |>  pull(),\n      TRUE ~ NA_character_\n    )\n  )\n  \np <- plot_data |> \n  filter(!(educ == \"na/other\" & condition == \"educ\")) |> \n  ggplot(aes(x = draw, y = cat_val)) +\n  stat_gradientinterval(\n    slab_size = 3,  \n    #normalize = \"xy\", \n    show_interval = FALSE,\n    show_point = FALSE,   \n    colour=\"#525252\",\n   fill=\"#525252\"\n  )  +\n  \n  geom_spoke(data = . %>% group_by(model, condition, cat_val) %>% summarise(draw=mean(draw)), angle=get_radians(90), radius=.5, position=\"center_spoke\",alpha=1, linewidth=.5, colour=\"#525252\") + \n  \n  scale_x_continuous(labels = scales::label_percent(), breaks=c(.5,.7,.9)) +\n  labs(\n    x = \"Predicted probability of **good** health\", y = NULL,\n    title = \"Predicting over demographics by **model**\") +\n  theme(panel.grid.minor = element_blank(), panel.grid.major.y = element_blank()) +\n  geom_vline(xintercept=.777, colour=\"#525252\", linewidth=.2) +\n  coord_cartesian(xlim = c(.45, 1)) + \n  facet_grid(condition~model, scales=\"free_y\", space=\"free_y\") +\n  theme(\n    axis.title = element_markdown(size=35),\n    plot.title = element_markdown(size=60),\n    axis.text = element_text(size=30),\n    strip.text = element_text(size=30)\n  )\nggsave(here(\"..\", \"figs\", \"predictions.png\"), p, width=6.5, height=5, dpi=300)\n```\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../figs/predictions.png){#fig-predictions width=100%}\n:::\n:::\n\n\nHere I use `avg_comparisons()` to analyse the average marginal component effect of moving between age ranges, education levels etc. holding other features constant. So with marginal effects, we ask what happens to an outcome when the explanatory variable moves, in this case, between levels. This corresponds with how one would normally interpret coefficients from a regression model.\n\nThis function works as follows, as per [`marginaleffects` documentation](https://marginaleffects.com/chapters/comparisons.html):\n\n> 1. Compute predictions for every row of the dataset in the counterfactual world where all observations belong to the treatment condition.\n> 2. Compute predictions for every row of the dataset in the counterfactual world where all observations belong to the control condition.\n> 3. Take the differences between the two vectors of predictions.\n> 4. Average the unit-level estimates across the whole dataset, or within subgroups.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Time difference of 2.9 mins\nstart <- Sys.time() \nmodel_effects <- map2_df(\n  .x = list(model1, model7), \n  .y = c(\"model1\", \"model7\"),\n  ~ map_df(model_var_levels |> filter(model == .y) |> pull(variable) |> unique(),\n           function(var) {\n             avg_comparisons(.x, variable = var, allow_new_levels = TRUE) |> \n               posterior_draws() |> \n               add_column(condition= var, model = .y)\n           })\n)\nprint(Sys.time()-start)\n\n\neffects_nested <- model_effects %>% \n  separate_wider_delim(\n    contrast,\n    delim = \" - \", \n    names = c(\"variable_level\", \"reference_level\")\n  ) %>% \n  group_by(variable_level, reference_level, model) %>% \n  nest()\n\n\nmap2_df(\n  .x = list(model1, model7), \n  .y = c(\"model1\", \"model7\"),\n  ~ map_df(model_var_levels |> filter(model == .y) |> pull(variable) |> unique()\n\n\nplot_data <- model_var_levels |> \n  left_join(\n    effects_nested,\n    by = join_by(levels == variable_level, model == model)\n  ) |> \n  mutate(data = map_if(data, is.null, ~ tibble(draw = 0, estimate = 0))) |> \n  unnest(data) \n\nplot_data_m1 <- plot_data |> filter(model ==\"model1\") |> \n  pivot_wider(names_from=condition, values_from=levels) |> \n  mutate(age2 = case_when(\n      str_detect(age2, \"age\\\\d+p$\") ~ str_replace(age2, \"age(\\\\d+)p\", \"\\\\1+\"),\n      str_detect(age2, \"age\\\\d+to\\\\d+\") ~ str_replace(age2, \"age(\\\\d+)to(\\\\d+)\", \"\\\\1 - \\\\2\"),\n      is.na(age2) ~ \"0 - 15\",\n      TRUE ~ age2),\n    cat_val = case_when(\n      variable == \"age2\" ~ pick(age2) |>  pull(),\n      TRUE ~ NA_character_\n    )\n  ) |> \n  select(model, variable, draw, cat_val)\n  \nplot_data_m7 <- plot_data |> filter(model ==\"model7\") |> \n  pivot_wider(names_from=condition, values_from=levels) |> \n  mutate(age2 = case_when(\n      str_detect(age2, \"age\\\\d+p$\") ~ str_replace(age2, \"age(\\\\d+)p\", \"\\\\1+\"),\n      str_detect(age2, \"age\\\\d+to\\\\d+\") ~ str_replace(age2, \"age(\\\\d+)to(\\\\d+)\", \"\\\\1 - \\\\2\"),\n      is.na(age2) ~ \"0 - 15\",\n      TRUE ~ age2),\n    imd=case_when(\n      imd==\"1\" ~ \"1 most\",\n      imd== \"5\" ~ \"5 least\",\n      is.na(imd) ~ \"1 most\",\n      TRUE ~ imd\n      ),\n    region=case_when(\n      region==\"East_Midlands\" ~ \"EM\",\n      region==\"East_of_England\" ~ \"E\", \n      region==\"North_East\" ~ \"NE\",\n      region==\"North_West\" ~ \"NW\",\n      region==\"South_East\" ~ \"SE\",\n      region==\"South_West\" ~ \"SW\",\n      region==\"West_Midlands\" ~ \"WM\",\n      region==\"Yorkshire_and_the_Humber\" ~ \"Y&H\",\n      is.na(region) ~ \"EM\",\n      TRUE ~ region),\n    educ=case_when(\n      educ==\"level0\" ~ \"0. none\",\n      educ==\"level1level2\" ~ \"1. 2+ GCSEs\", \n      educ==\"level3\" ~ \"3. A-levels\", \n      educ==\"level4\" ~ \"4. degree +\",\n      educ==\"na\" ~ \"na/other\",\n      educ==\"other\" ~ \"na/other\",\n      is.na(educ) ~ \"0. none\",\n      TRUE ~ educ\n      ),\n    is_urban=case_when(\n      is_urban == FALSE ~ \"rural\",\n      is_urban == TRUE ~ \"urban\",\n      is.na(is_urban) ~ \"rural\",\n      TRUE ~ is_urban\n      ),\n    cat_val = case_when(\n      variable == \"age2\" ~ pick(age2) |>  pull(),\n      variable == \"educ\" ~ pick(educ) |>  pull(),\n      variable == \"region\" ~ pick(region) |>  pull(),\n      variable == \"imd\" ~ pick(imd) |>  pull(),\n      variable == \"is_urban\" ~ pick(is_urban) |>  pull(),\n      TRUE ~ NA_character_\n    )\n  ) |> \n  select(model, variable, draw, cat_val)\n\nplot_data <- bind_rows(plot_data_m1, plot_data_m7)  \n\np <- plot_data |> \n ggplot(aes(x = draw, y = cat_val)) +\n  stat_gradientinterval(\n    slab_size = 3,  \n    #normalize = \"xy\", \n    show_interval = FALSE,\n    show_point = FALSE,   \n    colour=\"#525252\",\n   fill=\"#525252\"\n  )  +\n  \n  geom_spoke(data = . %>% group_by(model, variable, cat_val) %>% summarise(draw=mean(draw)), angle=get_radians(90), radius=.5, position=\"center_spoke\",alpha=1, linewidth=.5, colour=\"#525252\") + \n  \n  \n  theme(panel.grid.minor = element_blank(), panel.grid.major.y = element_blank()) +\n  geom_vline(xintercept=0, colour=\"#525252\", linewidth=.2) +\n  \n  scale_x_continuous(labels = scales::label_percent()) +\n  \n  facet_grid(variable~model, scales=\"free_y\", space=\"free_y\") +\n  \n  #facet_grid(variable~., scales=\"free_y\", space=\"free_y\") +\n   labs(\n    y = NULL,\n    title = \"Posterior 'marginal effects'\",\n    #subtitle = \"-- moving between levels of explanatory variables\",\n    x=\"% change in **good** health from control level\", y=\"\"\n  ) +\n  theme(\n    axis.title = element_markdown(size=35),\n    plot.title = element_markdown(size=60),\n    plot.subtitle = element_markdown(size=35),\n    axis.text = element_text(size=30),\n    strip.text = element_text(size=30)\n  )\nggsave(here(\"..\", \"figs\",\"comparisons.png\"), p, width=6.5, height=5, dpi=300)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../figs/comparisons.png){#fig-comparisons width=100%}\n:::\n:::\n\n\n\n## Example poststratification\n\nAt poststratification, we predict over the outcome for each of the 'strata' defined by the poststratification frame (`ps`). I've wrapped this into a function so that we poststratify per model. Here I also calculate absolute errors for each postratification model prediction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict over binary outcome mode\nps_health <-  function(model, model_spec, ps) {\n  p <- model |> \n  add_epred_draws(newdata = ps, ndraws=500, allow_new_levels = TRUE) |>\n  rename(pred_good_health = .epred) |>\n  mutate(pred_good_health_prop = pred_good_health * prop) |> \n  ungroup() |> \n  summarise(pred_good_health = sum(pred_good_health_prop),\n            .by = c(zone_id, .draw)) |> \n  summarise(\n    mean = mean(pred_good_health),\n    lower = quantile(pred_good_health, 0.025),\n    upper = quantile(pred_good_health, 0.975),\n    .by = zone_id\n  ) |> \n  left_join(health |> mutate(obs_good = good+verygood) |> select(zone_id, obs_good)) |> \n  left_join(zone_totals) |> \n  mutate(\n    exp_good=mean*hhd, \n    exp_notgood=hhd-exp_good,\n    obs_notgood=hhd-obs_good,\n    sum_tae=abs(exp_good-obs_good) + abs(exp_notgood-obs_notgood),\n    prop_tae=sum_tae/hhd\n    ) |> \n  pivot_longer(cols=c(exp_good, exp_notgood, obs_good, obs_notgood), values_to=\"count\", names_to=\"type\") |> \n  separate_wider_delim(col=type, names=c(\"type\", \"health\"), delim=\"_\") |> \n  pivot_wider(names_from = type, values_from = count) |> \n  add_column(mrp=model_spec)\n \n  return(p)\n}\n```\n:::\n\n\n\nI then post-stratify over each model, within a `purrr::map()`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmrp_results <- map2_df(\n  .x=list(model1, model), \n  .y=c(\"model1\", \"model7\"),\n  ~ps_health(.x, .y, ps2 |> mutate(age2=age))\n)\n```\n:::\n\n\nResults from the `FMF` (spatial microsimulation model) are stored in a separate `.csv` file. After loading into the session, I refactor this data frame so that it can be joined, with `bind_rows`, on the MRP results.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nSo `bind_rows()` on MRP and FMF results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- bind_rows(\n  fmf_results |> filter(spec %in% c(\"sex_age\", \"educ_imd_region\")) |> \n    mutate(spec=if_else(spec==\"sex_age\", \"model1\", \"model7\"), mean=0, lower=0, upper=0) , \n  mrp_results |> filter(!is.na(hhd)) |>  rename(spec=mrp) |> \n    mutate(type=\"mrp\")  #|> select(-c(mean, lower, upper))\n) |> \nfilter(spec!=\"Census\", spec!=\"RM42_46_120_SxA_qimd19\") |> \n  filter(!is.na(hhd)) |> \n  mutate(\n    perc_obs=obs/hhd, perc_exp=exp/hhd, perc_tae=abs(perc_obs-perc_exp),\n    resid=(obs-exp)/sqrt(exp)\n  ) \n```\n:::\n\n\n\nAnother external table is that describing Information Entropy scores, per area, on the outcome estimates derived from the spatial microsimulation. This describes how much our models need to draw from a diminishing set of survey respondents, as we constrain on more variables.\n\n\n::: {.cell}\n\n:::\n\n\n\n## Example SAE evaluation\n\nStaging data for plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_data <- results |> filter(health==\"good\") |> \n mutate(resid=(obs-exp)/sqrt(exp), perc_obs=obs/hhd, perc_exp=exp/hhd) |> \n  group_by(type, spec) |> \n  mutate(\n    resid_est=mean(resid), resid_var=sd(resid),\n    obs_est=mean(obs), obs_var=sd(obs),\n    exp_est=mean(exp), exp_var=sd(exp)\n  ) |> ungroup() |> \n  select(zone_id, type, spec, resid_val=resid, resid_est, resid_var, \n         obs_val=obs, exp_val=exp, obs_est, obs_var, exp_est, exp_var, perc_obs, perc_exp, sum_tae, prop_tae, perc_tae) |> \n  pivot_longer(-c(zone_id, type, spec, sum_tae, prop_tae, perc_tae), names_to=\"stat\") |> \n  separate_wider_delim(stat, delim=\"_\", names=c(\"stat\", \"stat_type\")) |> \n  pivot_wider(names_from=stat_type, values_from=value) |> \n  mutate(lower=est-2*(var/sqrt(6842)), upper=est+2*(var/sqrt(6842))) |> \n  mutate(\n    spec=factor(spec, levels=c(\"model1\", \"model7\"))\n  ) \n```\n:::\n\n\n\nFor plots evaluating model performance, I generate several helper functions. These are quite specialised to the HSE case, so I need to return to these to generalise when doing comparisons on other model case studies.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Map residuals\nmap_resids <- function(dat, censor) {\n  \n  # Spatial extent of geog.\n  bbox <- st_bbox(dat)\n  map_width <- bbox$xmax-bbox$xmin\n  map_height <- bbox$ymax-bbox$ymin\n  \n  # Draw map\n  map <- dat |> \n    mutate(resid=pmin(resid,censor)) |> \n  ggplot() +\n  geom_sf(data=. %>% summarise(), fill=\"transparent\", linewidth=.45, colour=\"#525252\") +\n  geom_sf(aes(fill=resid), linewidth=0) +\n  geom_sf(data=. %>% group_by(region) %>% summarise(), fill=\"transparent\", linewidth=.25, colour=\"#ffffff\") +\n  coord_sf(xlim = c(unname(bbox$xmin)+.2*map_width, unname(bbox$xmax)+.5*map_width)) +\n  scale_fill_distiller(palette=\"RdBu\", limits=c(-censor,censor), direction=1)   +\n  # Annotate model performance.\n    geom_text(data = . %>% summarise(),\n    aes(x=bbox$xmax+.2*map_width, y=bbox$ymax-.2*map_height, label=\"MAE\"), hjust=\"right\",vjust=\"top\", size=6.5, colour=\"#525252\",\n  ) +\n  geom_text(data = . %>% summarise(mae = mean(sum_tae),perc_mae= mean(perc_tae)),\n    aes(x=bbox$xmax+.2*map_width, y=bbox$ymax-.28*map_height, label=paste0(\"# \", round(mae,0))), hjust=\"right\",vjust=\"top\", size=6.5, colour=\"#525252\",\n  ) +\n  geom_text(data = . %>% summarise(mae = mean(sum_tae),perc_mae= mean(perc_tae)),\n    aes(x=bbox$xmax+.2*map_width, y=bbox$ymax-.36*map_height, label=paste0(\"% \",round(perc_mae*100,1))), hjust=\"right\",vjust=\"top\", size=6.5, colour=\"#525252\",\n  ) +\n  # Strip out chart assembly.\n  guides(fill=\"none\") +\n  theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA), \n    axis.text.x = element_blank(), axis.line = element_blank(), \n    axis.text.y = element_blank(), axis.title.x = element_blank(), \n    axis.title.y = element_blank(), \n    plot.margin = margin(0, 0, 0, 0, \"pt\")\n  )\n  \n  bars <- dat |> st_drop_geometry() |>  \n     mutate(resid=pmin(resid,censor)) |>\n    ggplot(aes(x=resid)) +\n    geom_histogram(aes(fill = after_stat(x)), linewidth=0) +\n    geom_step(stat = \"bin\", colour = \"#525252\", linewidth = .15, \n           position = position_nudge(x=-.55)) +\n  \n  # Fill with the same palette as the map\n  scale_fill_distiller(palette=\"RdBu\", limits=c(-censor,censor), direction=1, guide=\"none\")   +\n  scale_x_continuous(limits = c(-censor, censor), expand=c(0, 0)) +\n  scale_y_continuous(expand=c(0, 0)) +\n  labs(x = \"\") +\n  theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA),\n      plot.margin = margin(0, 0, 0, 0, \"pt\"),\n    axis.text.y=element_blank(), axis.title.y=element_blank(), \n    axis.line = element_blank(), axis.text.x = element_blank()\n  )\n  \n  return(map + inset_element(bars,.65,-.1,1,.55))\n}\n# Map Entropy / Prediction intervals\nmap_intervals <- function(dat, max_scaled) {\n  \n  # Spatial extent of geog.\n  bbox <- st_bbox(dat)\n  map_width <- bbox$xmax-bbox$xmin\n  map_height <- bbox$ymax-bbox$ymin\n  \n  map <- dat |> \n    mutate(interval = interval/max_scaled) |> \n  ggplot() +\n  geom_sf(data=. %>% summarise(), fill=\"transparent\", linewidth=.4, colour=\"#525252\") +\n  geom_sf(aes(fill=interval), linewidth=0) +\n  geom_sf(data= . %>% group_by(region) %>% summarise(), fill=\"transparent\", linewidth=.25, colour=\"#ffffff\") +\n    coord_sf(xlim = c(unname(bbox$xmin)+.1*map_width, unname(bbox$xmax)+.5*map_width)) +\n    scale_fill_distiller(palette=\"Blues\", limits=c(0,1), direction=1, breaks = c(0.1,.9)) +\n    guides(fill=\"none\") +\n    theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA), \n    axis.text.x = element_blank(), axis.line = element_blank(), \n    axis.text.y = element_blank(), axis.title.x = element_blank(), \n    axis.title.y = element_blank(), \n    plot.margin = margin(0, 0, 0, 0, \"pt\")\n  )\n  \n  bars <- dat |> st_drop_geometry() |>  \n    mutate(interval = interval/max_scaled) |>\n    ggplot(aes(x=interval)) +\n    geom_histogram(aes(fill = after_stat(x)), linewidth=0) +\n    geom_step(stat = \"bin\", colour = \"#525252\", linewidth = .1, \n           position = position_nudge(x=-.015)) +\n  \n  # Fill with the same palette as the map\n  scale_fill_distiller(palette=\"Blues\", limits=c(0,1), direction=1, breaks = c(0.1,.9), guide=\"none\") +\n  scale_x_continuous(limits = c(0, 1), expand=c(0, 0)) +\n  scale_y_continuous(expand=c(0, 0)) +\n  labs(x = \"\") +\n  theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA),\n      plot.margin = margin(0, 0, 0, 0, \"pt\"),\n    axis.text.y=element_blank(), axis.title.y=element_blank(), \n    axis.line = element_blank(), axis.text.x = element_blank()\n  )\n  \n  return(map + inset_element(bars,.65,-.1,1,.55))\n  \n}\n# Map shannon\nmap_shannon <- function(dat, max_scaled) {\n  \n  # Spatial extent of geog.\n  bbox <- st_bbox(dat)\n  map_width <- bbox$xmax-bbox$xmin\n  map_height <- bbox$ymax-bbox$ymin\n  \n  map <- dat |> \n    mutate(entropy = shannon/max_scaled) |> \n  ggplot() +\n  geom_sf(data=. %>% summarise(), fill=\"transparent\", linewidth=.4, colour=\"#525252\") +\n  geom_sf(aes(fill=entropy), linewidth=0) +\n  geom_sf(data= . %>% group_by(region) %>% summarise(), fill=\"transparent\", linewidth=.25, colour=\"#ffffff\") +\n    coord_sf(xlim = c(unname(bbox$xmin)+.1*map_width, unname(bbox$xmax)+.5*map_width)) +\n    scale_fill_distiller(palette=\"Blues\", limits=c(0,1), direction=-1, breaks = c(0.1,.9)) +\n    guides(fill=\"none\") +\n    theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA), \n    axis.text.x = element_blank(), axis.line = element_blank(), \n    axis.text.y = element_blank(), axis.title.x = element_blank(), \n    axis.title.y = element_blank(), \n    plot.margin = margin(0, 0, 0, 0, \"pt\")\n  )\n  \n  bars <- dat |> st_drop_geometry() |>  \n    mutate(entropy = shannon/max_scaled) |>\n    ggplot(aes(x=entropy)) +\n    geom_histogram(aes(fill = after_stat(x)), linewidth=0) +\n    geom_step(stat = \"bin\", colour = \"#525252\", linewidth = .1, \n           position = position_nudge(x=-.015)) +\n  \n  # Fill with the same palette as the map\n  scale_fill_distiller(palette=\"Blues\", limits=c(0,1), direction=-1, breaks = c(0.1,.9), guide=\"none\") +\n  scale_x_continuous(limits = c(0, 1), expand=c(0, 0)) +\n  scale_y_continuous(expand=c(0, 0)) +\n  labs(x = \"\") +\n  theme(\n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA),\n      plot.margin = margin(0, 0, 0, 0, \"pt\"),\n    axis.text.y=element_blank(), axis.title.y=element_blank(), \n    axis.line = element_blank(), axis.text.x = element_blank()\n  )\n  \n  return(map + inset_element(bars,.65,-.1,1,.55))\n  \n}\n# Model labs\nmodel_labs<- function(spec) {\n p <-  ggplot() +\n    annotate(\"richtext\", x=0,y=.5, label=spec, hjust=\"left\",vjust=\"middle\", label.colour = NA, size=9, colour=\"#525252\", fill=\"transparent\") +\n   scale_x_continuous(limits=c(0,1), expand=c(0, 0)) +\n   scale_y_continuous(limits=c(0,1), expand=c(0, 0)) +\n  theme_void() +\n     theme(\n    plot.margin = unit(c(0, 0, 0, 0), \"pt\"),        \n    panel.background = element_rect(fill = NA, color = NA),  \n    plot.background = element_rect(fill = NA, color = NA)   \n  )\nreturn(p)\n}\n```\n:::\n\n\nI then iterate over each model and generate plot summaries: maps of residuals, of prediction intervals (MRP) and Information Emntropy (SPM).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsubsets_order <- c(\"model1\", \"model7\")\nsubsets <- tibble(type=c(rep(\"mrp\",2), rep(\"fmf\",2)), spec=rep(subsets_order,2))\np_resids <- pmap(subsets,  \n                 ~map_resids(\n                   dat=results |>\n                     filter(health==\"good\", type==..1, spec==..2) |> \n                     left_join(msoa_boundaries, by=c(\"zone_id\"=\"MSOA21CD\")) |> st_as_sf() |> \n                     left_join(geog |> select(zone_id, region)), \n                   censor=20)\n)\nmax_scaled <- results |> filter(type == \"mrp\") |> mutate(interval=upper-lower) |>  \n  group_by(spec) |> \n  summarise(max=max(interval))\np_intervals <- pmap(subsets |> filter(type == \"mrp\"), \n                 ~map_intervals(\n                   dat=results |>\n                     filter(type==..1, spec==..2) |> \n                     left_join(msoa_boundaries, by=c(\"zone_id\"=\"MSOA21CD\")) |> st_as_sf() |> \n                     left_join(geog |> select(zone_id, region)) |> \n                     mutate(interval=upper-lower),\n                   max_scaled |> filter(spec==..2) |> pull(max)\n                   )\n                 )\n\nmax_scaled <- shannon |> group_by(spec) |>  summarise(max=max(shannon)) \np_shannon <- pmap(subsets |> filter(type == \"fmf\"), \n                 ~map_shannon(\n                   dat=shannon |>\n                     filter(type==..1, spec==..2) |> \n                     left_join(msoa_boundaries, by=c(\"zone_id\"=\"MSOA21CD\")) |> st_as_sf() |> \n                     left_join(geog |> select(zone_id, region)),\n                    max_scaled |> filter(spec==..2) |> pull(max)\n                   )\n                 )\np_model_labs <- map(subsets |> filter(type==\"mrp\") |>  select(spec) |> pull(), ~model_labs(.x))\n\n# Generate patchwork plots for each model summary type\ncomposite_labs <- (p_model_labs[[1]] / p_model_labs[[2]])\ncomposite_resids_mrp <- (p_resids[[1]] / p_resids[[2]])\ncomposite_resids_spm <- (p_resids[[3]] / p_resids[[4]])\ncomposite_shannon <- (p_shannon[[1]] / p_shannon[[2]])\ncomposite_intervals <- (p_intervals[[1]] / p_intervals[[2]])\n\n# View composition of each of these summaries.\ncomp_plot <- (composite_labs | composite_resids_mrp | composite_intervals |  composite_resids_spm | composite_shannon) + plot_layout(widths=c(.25,1,.9, 1,.9))\ncomp_plot_gg <- patchworkGrob(comp_plot)\n\n# Annotate composed plots.\np <- ggplot() +\n  scale_y_continuous(limits=c(-.1,1.05), expand=c(0, 0)) +\n  scale_x_continuous(limits=c(0,1.05), expand=c(0, 0)) +\n  annotation_custom(comp_plot_gg, xmin = 0, ymin = 0, xmax = 1, ymax = 1) +\n\n  theme(\n    axis.title.x=element_blank(), axis.title.y=element_blank(),\n    axis.text = element_blank(), axis.line = element_blank(),\n    plot.margin = unit(c(0, 0, 0, 0), \"pt\"),       \n    panel.background = element_rect(fill = \"#ffffff\", color = NA),  \n    plot.background = element_rect(fill = \"#ffffff\", color = NA)    \n  ) +\n  \n  \n  # Model titles\n    annotate(\"richtext\", x=.25,y=1.05, hjust=\"left\",vjust=\"top\", label.colour = NA, size=12, colour=\"#525252\", fill=\"transparent\",\n           label=\"MRP\" ) +\n    annotate(\"richtext\", x=.73,y=1.05, hjust=\"left\",vjust=\"top\", label.colour = NA, size=12, colour=\"#525252\", fill=\"transparent\",\n           label=\"SPM\" ) +\n\n  \n  # Legends: fiddly use of annotate, as <br> unexpected in ggtext.\n  annotate(\"segment\", x=0,y=0, xend=1.05, yend=0, colour=\"#525252\", linewidth=.1) +\n\n    annotate(\"richtext\", x=.08,y=0, hjust=\"left\",vjust=\"top\", label.colour = NA, \n  size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"Residuals: obs-model / sqrt(model)\" ) +\n    annotate(\"richtext\", x=.1,y=-.03, hjust=\"left\",vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"<span style='color: #b2182b'>**underestimate**</span> |\n           <span style='color: #2166ac;'>**overestimate**</span>\" ) +\n  \n   annotate(\"richtext\", x=.31,y=.0, hjust=\"left\",vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"Prediction intervals\") +\n  annotate(\"richtext\", x=.31,y=-.03, hjust=\"left\",vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"<span style='color: #9ecae1;'>**narrower**</span> | <span style='color: #084594;'>**wider**</span>\") +\n           \n  annotate(\"richtext\", x=.8,y=.0, hjust=\"left\",vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"Entropy\") +\n    annotate(\"richtext\", x=.8, y=-.03, hjust=\"left\",vjust=\"top\", \n             label.colour = NA, size=6.5, colour=\"#525252\", \n             fill=\"transparent\",\n             label = \"<span style='color: #9ecae1;'>**high diversity**</span> | <span style='color: #084594;'>**low diversity**</span><br>~ more respondents\") +\n      \n  annotate(\"richtext\", x=.55,y=0, hjust=\"left\", vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"Mean abs error:\" ) +\n    annotate(\"richtext\", x=.55,y=-.03, hjust=\"left\", vjust=\"top\", label.colour = NA, size=6.5, colour=\"#525252\", fill=\"transparent\",\n           label=\"<span># good & bad | % good</span>\" ) +\n  \n  annotate(\"text\", x=.67,y=.065, hjust=\"left\",vjust=\"top\",  size=6.5, colour=\"#525252\", \n           label=\"Extreme estimates\") +\n  annotate(\"text\", x=.67,y=.035, hjust=\"left\",vjust=\"top\",  size=6.5, colour=\"#525252\", \n           label=\"are censored\") +\n  annotate(\"curve\", x=.72, xend=.76, y=.075, yend=.12, linewidth=.2, colour=\"#525252\", arrow = arrow(length = unit(0.006, \"npc\")), curvature = -0.4)  \n\nggsave(here(\"..\", \"figs\", \"model_summary.png\"), p, width=8, height=4, dpi=300)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../figs/model_summary.png){#fig-models width=100%}\n:::\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}